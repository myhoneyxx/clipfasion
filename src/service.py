import tempfile
import os
from typing import List, Tuple, Optional
from PIL import Image

from .common import AppConfig, init_logger
from .dao import UserBehaviorDAO, ImageDAO, IndexDAO

logger = init_logger("Service")


# -------------------------- æœç´¢æœåŠ¡ï¼ˆå•ä¸€èŒè´£ï¼šæœç´¢ä¸šåŠ¡é€»è¾‘ï¼‰- å…³é”®è°ƒæ•´ --------------------------
class SearchService:
    def __init__(self, config: AppConfig, clip_matcher, image_dao: ImageDAO, behavior_dao: UserBehaviorDAO):
        self.config = config
        self.clip_matcher = clip_matcher  # ä¾èµ–æ³¨å…¥ï¼Œè§£è€¦CLIPå®ç°
        self.image_dao = image_dao  # ä¾èµ–æ³¨å…¥ï¼Œè§£è€¦å›¾ç‰‡æ“ä½œ
        self.behavior_dao = behavior_dao  # ä¾èµ–æ³¨å…¥ï¼Œè§£è€¦è¡Œä¸ºæ“ä½œ

    def text_search(self, query: str, top_k: int) -> List[Image.Image]:
        """æ–‡æœ¬æœç´¢ï¼ˆè§£è€¦æœç´¢é€»è¾‘ä¸æ•°æ®æ“ä½œï¼‰- æ— è°ƒæ•´ï¼ˆCLIPMatcheræ¥å£åŒ¹é…ï¼‰"""
        if not query.strip() or top_k < 1:
            return []

        # è®°å½•è¡Œä¸ºï¼ˆä¸šåŠ¡è§„åˆ™ï¼šæœç´¢åè®°å½•ï¼‰
        self.behavior_dao.add_behavior("search_history", query.strip())

        try:
            # CLIPMatcher.search_images_by_text è¿”å› (è·¯å¾„, åˆ†æ•°) åˆ—è¡¨ï¼Œæ¥å£åŒ¹é…
            results = self.clip_matcher.search_images_by_text(query.strip(), top_k=top_k)
            return [self.image_dao.load_image(path) or self.image_dao.get_placeholder() for path, _ in results]
        except Exception as e:
            logger.error(f"æ–‡æœ¬æœç´¢å¤±è´¥: {str(e)}")
            return []

    def image_search(self, query_image: Image.Image, top_k: int) -> List[Image.Image]:
        """å›¾åƒæœç´¢ï¼ˆå…³é”®è°ƒæ•´ï¼šCLIPMatcherè¦æ±‚ä¼ å…¥å›¾ç‰‡è·¯å¾„ï¼Œéœ€ä¸´æ—¶ä¿å­˜PILå¯¹è±¡ï¼‰"""
        if not query_image or top_k < 1:
            return []

        try:
            # å…³é”®è°ƒæ•´ï¼šCLIPMatcher.search_images_by_image éœ€è¦ä¼ å…¥å›¾ç‰‡è·¯å¾„ï¼Œè€ŒéPILå¯¹è±¡
            # ä¸´æ—¶ä¿å­˜PILå›¾ç‰‡ä¸ºæ–‡ä»¶
            with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tmp_file:
                query_image.convert("RGB").save(tmp_file, format='JPEG', quality=95)
                tmp_path = tmp_file.name

            # è°ƒç”¨CLIPMatcheræ¥å£ï¼ˆä¼ å…¥ä¸´æ—¶æ–‡ä»¶è·¯å¾„ï¼‰
            results = self.clip_matcher.search_images_by_image(
                query_image_path=tmp_path,
                top_k=top_k
            )

            # åŠ è½½ç»“æœå›¾ç‰‡
            images = [self.image_dao.load_image(path) or self.image_dao.get_placeholder() for path, _ in results]

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)

            return images
        except Exception as e:
            logger.error(f"å›¾åƒæœç´¢å¤±è´¥: {str(e)}")
            return []


# -------------------------- æ¨èæœåŠ¡ï¼ˆå•ä¸€èŒè´£ï¼šæ¨èä¸šåŠ¡é€»è¾‘ï¼‰- å…³é”®è°ƒæ•´ --------------------------
class RecommendService:
    def __init__(self, config: AppConfig, clip_matcher, image_dao: ImageDAO, behavior_dao: UserBehaviorDAO):
        self.config = config
        self.clip_matcher = clip_matcher
        self.image_dao = image_dao
        self.behavior_dao = behavior_dao

    def get_personalized_recommend(self) -> Tuple[List[Image.Image], str]:
        """ä¸ªæ€§åŒ–æ¨èï¼ˆè§£è€¦æ¨èé€»è¾‘ä¸æ•°æ®æ“ä½œï¼‰"""
        behavior = self.behavior_dao.get_behavior()
        has_behavior = any([len(behavior["search_history"]) > 0, len(behavior["click_history"]) > 0])

        # å†·å¯åŠ¨ï¼šæ— è¡Œä¸ºæ—¶è¿”å›éšæœºæ¨è
        if not has_behavior:
            return self.image_dao.get_random_images(self.config.default_recommend_num), "ğŸ“± æš‚æ— ä¸ªæ€§åŒ–è¡Œä¸ºï¼Œä¸ºä½ æ¨èçƒ­é—¨å•†å“ï½"

        # ç”Ÿæˆæ¨èå€™é€‰é›†ï¼ˆä¸šåŠ¡æ ¸å¿ƒé€»è¾‘ï¼‰
        candidate_paths = self._generate_candidates(behavior)
        # åŠ è½½å›¾ç‰‡ï¼ˆè§£è€¦å›¾ç‰‡åŠ è½½ï¼‰
        recommendations = [self.image_dao.load_image(path) or self.image_dao.get_placeholder() for path in
                           candidate_paths]
        # è¡¥å……ä¸è¶³æ•°é‡
        while len(recommendations) < self.config.default_recommend_num:
            recommendations.append(self.image_dao.get_placeholder())

        return recommendations[:self.config.default_recommend_num], self._generate_reason(behavior)

    def _generate_candidates(self, behavior: dict) -> List[str]:
        """ç”Ÿæˆæ¨èå€™é€‰é›†ï¼ˆå…³é”®è°ƒæ•´ï¼šåŸºäºç‚¹å‡»å†å²çš„å›¾åƒæ¨èé€‚é…CLIPMatcheræ¥å£ï¼‰"""
        candidates = set()

        # 1. åŸºäºæœç´¢å†å²ï¼ˆæ— è°ƒæ•´ï¼Œæ¥å£åŒ¹é…ï¼‰
        recent_searches = behavior["search_history"][-self.config.recent_behavior_cnt:]
        for keyword in recent_searches:
            try:
                results = self.clip_matcher.search_images_by_text(keyword, top_k=self.config.top_k_recommend)
                candidates.update([path for path, _ in results])
            except Exception as e:
                logger.error(f"æœç´¢å†å²æ¨èå¤±è´¥: {str(e)}")

        # 2. åŸºäºç‚¹å‡»å†å²ï¼ˆå…³é”®è°ƒæ•´ï¼šCLIPMatcheréœ€è¦ä¼ å…¥å›¾ç‰‡è·¯å¾„ï¼‰
        recent_clicks = behavior["click_history"][-self.config.recent_behavior_cnt:]
        for path in recent_clicks:
            try:
                # ç›´æ¥ä¼ å…¥ç‚¹å‡»å•†å“çš„è·¯å¾„ï¼ˆæ— éœ€ä¸´æ—¶æ–‡ä»¶ï¼Œå› ä¸ºå·²ç»æ˜¯æ–‡ä»¶è·¯å¾„ï¼‰
                results = self.clip_matcher.search_images_by_image(
                    query_image_path=path,
                    top_k=self.config.top_k_recommend
                )
                candidates.update([p for p, _ in results])
            except Exception as e:
                logger.error(f"ç‚¹å‡»å†å²æ¨èå¤±è´¥ï¼ˆè·¯å¾„: {path}ï¼‰: {str(e)}")

        # 3. è¡¥å……éšæœºå›¾ç‰‡ï¼ˆä¿è¯å¤šæ ·æ€§ï¼‰
        candidate_list = list(candidates)
        if len(candidate_list) < self.config.default_recommend_num:
            all_paths = self.image_dao.get_image_paths()
            supplement = [p for p in all_paths if p not in candidates][
                         :self.config.default_recommend_num - len(candidate_list)]
            candidate_list.extend(supplement)

        return candidate_list

    def _generate_reason(self, behavior: dict) -> str:
        """ç”Ÿæˆæ¨èç†ç”±ï¼ˆè§£è€¦ç†ç”±ç”Ÿæˆé€»è¾‘ï¼‰"""
        reasons = []
        if len(behavior["search_history"]) > 0:
            reasons.append("æœç´¢è®°å½•")
        if len(behavior["click_history"]) > 0:
            reasons.append("ç‚¹å‡»åå¥½")
        return f"ğŸ¯ ä¸ªæ€§åŒ–æ¨èï¼ˆåŸºäºä½ çš„{('ã€'.join(reasons))}ï¼‰"


# -------------------------- è¡Œä¸ºè·Ÿè¸ªæœåŠ¡ï¼ˆå•ä¸€èŒè´£ï¼šè¡Œä¸ºè·Ÿè¸ªé€»è¾‘ï¼‰- æ— æ”¹åŠ¨ --------------------------
class BehaviorTrackService:
    def __init__(self, config: AppConfig, behavior_dao: UserBehaviorDAO, recommend_service: RecommendService):
        self.config = config
        self.behavior_dao = behavior_dao
        self.recommend_service = recommend_service  # ä¾èµ–æ³¨å…¥ï¼Œè§£è€¦æ¨èæœåŠ¡

    def track_recommend_click(self, click_index: int) -> Tuple[List[Image.Image], str]:
        """è·Ÿè¸ªæ¨èç‚¹å‡»å¹¶åˆ·æ–°æ¨èï¼ˆè§£è€¦è·Ÿè¸ªé€»è¾‘ä¸æ¨èé€»è¾‘ï¼‰"""
        if click_index < 0:
            return self.recommend_service.get_personalized_recommend()

        # è·å–å½“å‰æ¨èçš„å€™é€‰è·¯å¾„ï¼ˆå¤ç”¨æ¨èæœåŠ¡é€»è¾‘ï¼Œé¿å…é‡å¤ï¼‰
        behavior = self.behavior_dao.get_behavior()
        candidate_paths = self.recommend_service._generate_candidates(behavior)

        if 0 <= click_index < len(candidate_paths):
            self.behavior_dao.add_behavior("click_history", candidate_paths[click_index])
            logger.info(f"è·Ÿè¸ªæ¨èç‚¹å‡»: {candidate_paths[click_index]}")

        # åˆ·æ–°æ¨è
        return self.recommend_service.get_personalized_recommend()