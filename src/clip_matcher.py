import os
import pickle
from typing import List, Tuple

import faiss
import numpy as np
import pandas as pd
import torch
from PIL import Image
from tqdm import tqdm
from transformers import CLIPProcessor, CLIPModel


class CLIPMatcher:
    """åŸºäºCLIPçš„æ–‡æœ¬å’Œå›¾åƒåŒ¹é…ç³»ç»Ÿ"""

    def __init__(self, model_path: str = "../clip-vit-base-patch32", device: str = None):
        """
        åˆå§‹åŒ–CLIPåŒ¹é…å™¨

        Args:
            model_path: CLIPæ¨¡å‹è·¯å¾„
            device: è®¡ç®—è®¾å¤‡ ('cuda', 'cpu' æˆ– None è‡ªåŠ¨é€‰æ‹©)
        """
        self.partition_indexes = {}
        self.device = device if device else ('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")

        # åŠ è½½CLIPæ¨¡å‹å’Œå¤„ç†å™¨
        print("æ­£åœ¨åŠ è½½CLIPæ¨¡å‹...")
        self.model = CLIPModel.from_pretrained(model_path)
        self.processor = CLIPProcessor.from_pretrained(model_path)
        self.model.to(self.device)
        self.model.eval()

        # åˆå§‹åŒ–å­˜å‚¨
        self.image_paths = []
        self.image_features = None
        self.text_features = None
        self.captions = []

        # FAISSç´¢å¼•
        self.image_index = None
        self.text_index = None

        print("CLIPåŒ¹é…å™¨åˆå§‹åŒ–å®Œæˆ!")

    def encode_images(self, image_paths: List[str], batch_size: int = 32) -> np.ndarray:
        """
        æ‰¹é‡ç¼–ç å›¾åƒ

        Args:
            image_paths: å›¾åƒè·¯å¾„åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°

        Returns:
            å›¾åƒç‰¹å¾å‘é‡æ•°ç»„
        """
        features = []

        print(f"æ­£åœ¨ç¼–ç  {len(image_paths)} å¼ å›¾åƒ...")
        for i in tqdm(range(0, len(image_paths), batch_size)):
            batch_paths = image_paths[i:i + batch_size]
            batch_images = []

            for path in batch_paths:
                try:
                    image = Image.open(path).convert('RGB')
                    batch_images.append(image)
                except Exception as e:
                    print(f"æ— æ³•åŠ è½½å›¾åƒ {path}: {e}")
                    # åˆ›å»ºä¸€ä¸ªç©ºç™½å›¾åƒä½œä¸ºå ä½ç¬¦
                    batch_images.append(Image.new('RGB', (224, 224), color='white'))

            if batch_images:
                with torch.no_grad():
                    inputs = self.processor(images=batch_images, return_tensors="pt", padding=True)
                    inputs = {k: v.to(self.device) for k, v in inputs.items()}
                    image_features = self.model.get_image_features(**inputs)
                    image_features = image_features / image_features.norm(dim=-1, keepdim=True)
                    features.append(image_features.cpu().numpy())

        return np.vstack(features) if features else np.array([])

    def encode_texts(self, texts: List[str], batch_size: int = 32) -> np.ndarray:
        """
        æ‰¹é‡ç¼–ç æ–‡æœ¬

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°

        Returns:
            æ–‡æœ¬ç‰¹å¾å‘é‡æ•°ç»„
        """
        features = []

        print(f"æ­£åœ¨ç¼–ç  {len(texts)} æ¡æ–‡æœ¬...")
        for i in tqdm(range(0, len(texts), batch_size)):
            batch_texts = texts[i:i + batch_size]

            with torch.no_grad():
                inputs = self.processor(text=batch_texts, return_tensors="pt", padding=True, truncation=True)
                inputs = {k: v.to(self.device) for k, v in inputs.items()}
                text_features = self.model.get_text_features(**inputs)
                text_features = text_features / text_features.norm(dim=-1, keepdim=True)
                features.append(text_features.cpu().numpy())

        return np.vstack(features) if features else np.array([])

    def build_image_index(self, image_dir: str, save_path: str = "image_index.pkl"):
        """
        æ„å»ºå›¾åƒç´¢å¼•

        Args:
            image_dir: å›¾åƒç›®å½•è·¯å¾„
            save_path: ç´¢å¼•ä¿å­˜è·¯å¾„
        """
        # è·å–æ‰€æœ‰å›¾åƒè·¯å¾„
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
        self.image_paths = []

        for filename in os.listdir(image_dir):
            if any(filename.lower().endswith(ext) for ext in image_extensions):
                self.image_paths.append(os.path.join(image_dir, filename))

        print(f"æ‰¾åˆ° {len(self.image_paths)} å¼ å›¾åƒ")

        # ç¼–ç å›¾åƒ
        self.image_features = self.encode_images(self.image_paths)

        # æ„å»ºFAISSç´¢å¼•
        if len(self.image_features) > 0:
            dimension = self.image_features.shape[1]
            self.image_index = faiss.IndexFlatIP(dimension)  # ä½¿ç”¨å†…ç§¯ç›¸ä¼¼åº¦
            self.image_index.add(self.image_features.astype('float32'))

            # ä¿å­˜ç´¢å¼•
            index_data = {
                'image_paths': self.image_paths,
                'image_features': self.image_features,
                'image_index': faiss.serialize_index(self.image_index)
            }

            with open(save_path, 'wb') as f:
                pickle.dump(index_data, f)

            print(f"å›¾åƒç´¢å¼•å·²ä¿å­˜åˆ° {save_path}")

    def build_text_index(self, captions_file: str, save_path: str = "text_index.pkl"):
        """
        æ„å»ºæ–‡æœ¬ç´¢å¼•

        Args:
            captions_file: å›¾åƒæè¿°æ–‡ä»¶è·¯å¾„
            save_path: ç´¢å¼•ä¿å­˜è·¯å¾„
        """
        # è¯»å–å›¾åƒæè¿°
        try:
            df = pd.read_csv(captions_file)
            self.captions = df['caption'].tolist()
            caption_images = df['image'].tolist()
        except Exception as e:
            print(f"è¯»å–æè¿°æ–‡ä»¶å¤±è´¥: {e}")
            return

        print(f"æ‰¾åˆ° {len(self.captions)} æ¡å›¾åƒæè¿°")

        # ç¼–ç æ–‡æœ¬
        self.text_features = self.encode_texts(self.captions)

        # æ„å»ºFAISSç´¢å¼•
        if len(self.text_features) > 0:
            dimension = self.text_features.shape[1]
            self.text_index = faiss.IndexFlatIP(dimension)
            self.text_index.add(self.text_features.astype('float32'))

            # ä¿å­˜ç´¢å¼•
            index_data = {
                'captions': self.captions,
                'caption_images': caption_images,
                'text_features': self.text_features,
                'text_index': faiss.serialize_index(self.text_index)
            }

            with open(save_path, 'wb') as f:
                pickle.dump(index_data, f)

            print(f"æ–‡æœ¬ç´¢å¼•å·²ä¿å­˜åˆ° {save_path}")

    def build_partition_index(self, captions_file: str):
        """
        è¾…åŠ©å‡½æ•°ï¼šåŸºäº CSV ç±»åˆ«ä¿¡æ¯æ„å»ºåˆ†ç‰‡ç´¢å¼• (ä½œä¸º CLIPMatcher ç±»çš„æ–¹æ³•)

        Args:
            captions_file: åŒ…å« image å’Œ caption åˆ—çš„ CSV æ–‡ä»¶è·¯å¾„
        """
        print(f"\n[3/3] ğŸ° æ­£åœ¨æ„å»ºåˆ†ç‰‡ç´¢å¼• (è§£å†³ç±»åˆ«ä¸å¹³è¡¡)...")

        # 1. è¯»å–CSVè·å–ç±»åˆ«ä¿¡æ¯
        try:
            # ç¡®ä¿ pandas å·²åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥: import pandas as pd
            df = pd.read_csv(captions_file)
        except Exception as e:
            print(f"      âŒ è¯»å–æè¿°æ–‡ä»¶å¤±è´¥: {e}")
            return

        # 2. åˆ›å»ºæ–‡ä»¶ååˆ°ç±»åˆ«çš„æ˜ å°„å­—å…¸
        print("      æ­£åœ¨è§£æç±»åˆ«æ˜ å°„...")
        img_category_map = {}
        for _, row in df.iterrows():
            # ç¡®ä¿è½¬ä¸ºå­—ç¬¦ä¸²å¹¶å°å†™ï¼Œé˜²æ­¢ AttributeError
            fname = str(row['image'])
            caption = str(row['caption']).lower()

            # ç®€å•åˆ†ç±»è§„åˆ™
            if "footwear" in caption or "shoes" in caption:
                cat = "footwear"
            elif "apparel" in caption:
                cat = "apparel"
            else:
                cat = "others"
            img_category_map[fname] = cat

        # 3. å‡†å¤‡åˆ†æ¡¶å®¹å™¨
        partitions = {
            "apparel": {'paths': [], 'features': []},
            "footwear": {'paths': [], 'features': []},
            "others": {'paths': [], 'features': []}
        }

        # 4. éå† self ä¸­å·²ç»ç®—å¥½çš„æ‰€æœ‰å›¾ç‰‡å’Œç‰¹å¾
        # ä¿®æ­£ç‚¹ï¼šä½¿ç”¨ self.image_paths ä»£æ›¿ matcher.image_paths
        if not hasattr(self, 'image_paths') or not self.image_paths:
            print("      âš ï¸ è­¦å‘Š: å†…å­˜ä¸­æ²¡æœ‰å›¾åƒç‰¹å¾ï¼Œè¯·å…ˆè°ƒç”¨ build_image_indexã€‚")
            return

        total_images = len(self.image_paths)  # ğŸ‘ˆ å·²ä¿®æ­£ä¸º self

        print(f"      æ­£åœ¨å¯¹ {total_images} å¼ å›¾åƒè¿›è¡Œåˆ†ç±»æ‹†åˆ†...")

        count_hit = 0
        for idx, path in enumerate(self.image_paths):  # ğŸ‘ˆ å·²ä¿®æ­£ä¸º self
            filename = os.path.basename(path)
            # æŸ¥æ‰¾è¯¥å›¾ç‰‡çš„ç±»åˆ«ï¼Œæ‰¾ä¸åˆ°é»˜è®¤ä¸º others
            category = img_category_map.get(filename, "others")

            if category in partitions:
                partitions[category]['paths'].append(path)
                # ä¿®æ­£ç‚¹ï¼šä½¿ç”¨ self.image_features ä»£æ›¿ matcher.image_features
                partitions[category]['features'].append(self.image_features[idx])  # ğŸ‘ˆ å·²ä¿®æ­£ä¸º self
                count_hit += 1

        # 5. ä¿å­˜åˆ†ç‰‡ç´¢å¼•
        for cat_name, data in partitions.items():
            paths = data['paths']
            feats = data['features']

            if len(paths) > 0:
                # è½¬æ¢ä¸º FAISS éœ€è¦çš„ float32 numpy æ•°ç»„
                # ç¡®ä¿ numpy å·²å¯¼å…¥: import numpy as np
                feats_np = np.array(feats).astype('float32')

                # æ„å»º FAISS ç´¢å¼•
                # ç¡®ä¿ faiss å·²å¯¼å…¥
                dimension = feats_np.shape[1]
                sub_index = faiss.IndexFlatIP(dimension)
                sub_index.add(feats_np)

                # ä¿å­˜ä¸º pkl æ–‡ä»¶
                save_path = f"index_{cat_name}.pkl"
                index_data = {
                    'image_paths': paths,
                    'image_features': feats_np,
                    'image_index': faiss.serialize_index(sub_index)
                }

                try:
                    with open(save_path, 'wb') as f:
                        # ç¡®ä¿ pickle å·²å¯¼å…¥
                        pickle.dump(index_data, f)
                    print(f"      âœ… å·²ä¿å­˜åˆ†ç‰‡: {save_path} (åŒ…å« {len(paths)} æ¡)")
                except Exception as e:
                    print(f"      âŒ ä¿å­˜åˆ†ç‰‡ {save_path} å¤±è´¥: {e}")

    def load_image_index(self, index_path: str = "image_index.pkl"):
        """åŠ è½½å›¾åƒç´¢å¼•"""
        try:
            with open(index_path, 'rb') as f:
                index_data = pickle.load(f)

            self.image_paths = index_data['image_paths']
            self.image_features = index_data['image_features']
            self.image_index = faiss.deserialize_index(index_data['image_index'])

            print(f"å·²åŠ è½½å›¾åƒç´¢å¼•ï¼ŒåŒ…å« {len(self.image_paths)} å¼ å›¾åƒ")
            return True
        except Exception as e:
            print(f"åŠ è½½å›¾åƒç´¢å¼•å¤±è´¥: {e}")
            return False

    def load_text_index(self, index_path: str = "text_index.pkl"):
        """åŠ è½½æ–‡æœ¬ç´¢å¼•"""
        try:
            with open(index_path, 'rb') as f:
                index_data = pickle.load(f)

            self.captions = index_data['captions']
            self.caption_images = index_data['caption_images']
            self.text_features = index_data['text_features']
            self.text_index = faiss.deserialize_index(index_data['text_index'])

            print(f"å·²åŠ è½½æ–‡æœ¬ç´¢å¼•ï¼ŒåŒ…å« {len(self.captions)} æ¡æè¿°")
            return True
        except Exception as e:
            print(f"åŠ è½½æ–‡æœ¬ç´¢å¼•å¤±è´¥: {e}")
            return False

    def load_partition_indexes(self, index_dir="."):
        """
        åŠ è½½æ‰€æœ‰ index_xxx.pkl åˆ†ç‰‡æ–‡ä»¶åˆ°å†…å­˜

        Args:
            index_dir: ç´¢å¼•æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•

        Returns:
            bool: æ˜¯å¦æˆåŠŸåŠ è½½äº†è‡³å°‘ä¸€ä¸ªåˆ†ç‰‡
        """
        if not os.path.exists(index_dir):
            print(f"âŒ ç´¢å¼•ç›®å½•ä¸å­˜åœ¨: {index_dir}")
            return False

        count = 0
        # éå†ç›®å½•å¯»æ‰¾ index_*.pkl
        for filename in os.listdir(index_dir):
            # ä¸¥æ ¼åŒ¹é…æ–‡ä»¶åæ¨¡å¼ï¼Œæ’é™¤ image_index.pkl (å…¨å±€ç´¢å¼•) å’Œ text_index.pkl
            if filename.startswith("index_") and filename.endswith(".pkl"):
                # æå–ç±»åˆ«å: index_apparel.pkl -> apparel
                cat = filename.replace("index_", "").replace(".pkl", "")
                file_path = os.path.join(index_dir, filename)

                try:
                    with open(file_path, 'rb') as f:
                        data = pickle.load(f)

                    # ç®€å•æ ¡éªŒæ•°æ®ç»“æ„ï¼Œé˜²æ­¢åŠ è½½æŸåæ–‡ä»¶
                    if 'image_paths' not in data or 'image_index' not in data:
                        print(f"âš ï¸ è·³è¿‡æ— æ•ˆç´¢å¼•æ–‡ä»¶: {filename}")
                        continue

                    # ååºåˆ—åŒ–å¹¶å­˜å‚¨
                    # æ³¨æ„ï¼šç¡®ä¿ __init__ ä¸­å·²ç»åˆå§‹åŒ–äº† self.partition_indexes = {}
                    self.partition_indexes[cat] = {
                        'paths': data['image_paths'],
                        'index': faiss.deserialize_index(data['image_index'])
                    }
                    print(f"âœ… å·²åŠ è½½åˆ†ç‰‡ç´¢å¼•: {cat} (åŒ…å« {len(data['image_paths'])} æ¡æ•°æ®)")
                    count += 1
                except Exception as e:
                    print(f"âŒ åŠ è½½åˆ†ç‰‡ {filename} å¤±è´¥: {e}")

        return count > 0
    # ğŸš¨ NEW FUNCTION: åŸºäºå‘é‡çš„ç›´æ¥æœç´¢æ¥å£ (æ”¯æŒç”¨æˆ·å…´è¶£å‘é‡)
    def search_images_by_vector(self, query_vector: np.ndarray, top_k: int = 5) -> List[Tuple[str, float]]:
        """
        æ ¹æ® CLIP ç‰¹å¾å‘é‡æœç´¢ç›¸ä¼¼å›¾åƒ (æ”¯æŒç”¨æˆ·å…´è¶£å‘é‡)

        Args:
            query_vector: å½’ä¸€åŒ–åçš„ CLIP ç‰¹å¾å‘é‡ (NumPy æ•°ç»„)
            top_k: è¿”å›å‰kä¸ªç»“æœ

        Returns:
            (å›¾åƒè·¯å¾„, ç›¸ä¼¼åº¦åˆ†æ•°) çš„åˆ—è¡¨
        """
        if self.image_index is None:
            return []

        # ç¡®ä¿å‘é‡æ˜¯ float32 ç±»å‹ï¼Œå¹¶ç¡®ä¿å…¶å½¢çŠ¶ä¸º (1, dimension)
        if query_vector.ndim == 1:
            query_vector = query_vector.reshape(1, -1)

        query_vector = query_vector.astype('float32')

        # æœç´¢
        scores, indices = self.image_index.search(query_vector, top_k)

        results = []
        for score, idx in zip(scores[0], indices[0]):
            if idx < len(self.image_paths):
                results.append((self.image_paths[idx], float(score)))

        return results

    def search_images_by_text(self, query_text: str, top_k: int = 5) -> List[Tuple[str, float]]:
        """
        æ ¹æ®æ–‡æœ¬æœç´¢ç›¸ä¼¼å›¾åƒ
        """
        if self.image_index is None:
            return []

        # ç¼–ç æŸ¥è¯¢æ–‡æœ¬
        query_features = self.encode_texts([query_text])

        # æœç´¢
        scores, indices = self.image_index.search(query_features.astype('float32'), top_k)

        results = []
        for score, idx in zip(scores[0], indices[0]):
            if idx < len(self.image_paths):
                results.append((self.image_paths[idx], float(score)))

        return results

    def search_images_by_image(self, query_image_path: str, top_k: int = 5) -> List[Tuple[str, float]]:
        """
        æ ¹æ®å›¾åƒæœç´¢ç›¸ä¼¼å›¾åƒ
        """
        if self.image_index is None:
            return []

        # ç¼–ç æŸ¥è¯¢å›¾åƒ
        query_features = self.encode_images([query_image_path])

        # æœç´¢
        scores, indices = self.image_index.search(query_features.astype('float32'), top_k + 1)  # +1 å› ä¸ºå¯èƒ½åŒ…å«è‡ªå·±

        results = []
        for score, idx in zip(scores[0], indices[0]):
            if idx < len(self.image_paths):
                image_path = self.image_paths[idx]
                # è·³è¿‡æŸ¥è¯¢å›¾åƒæœ¬èº«
                if os.path.abspath(image_path) != os.path.abspath(query_image_path):
                    results.append((image_path, float(score)))
                    if len(results) >= top_k:
                        break

        return results

    def search_in_partition(self, query_vector: np.ndarray, category: str, top_k: int = 5):
        """
        åœ¨æŒ‡å®šçš„åˆ†ç‰‡ç´¢å¼•ä¸­æœç´¢ç›¸ä¼¼å›¾åƒ

        Args:
            query_vector: æŸ¥è¯¢å‘é‡ (numpy array)
            category: åˆ†ç‰‡ç±»åˆ«åç§° (å¦‚ 'apparel', 'footwear')
            top_k: æœŸæœ›è¿”å›çš„ç»“æœæ•°é‡

        Returns:
            List[Tuple[str, float]]: [(å›¾ç‰‡è·¯å¾„, ç›¸ä¼¼åº¦åˆ†æ•°), ...]
        """
        # 1. æ£€æŸ¥è¯¥åˆ†ç‰‡æ˜¯å¦å­˜åœ¨
        if category not in self.partition_indexes:
            # å¦‚æœæ²¡æœ‰è¿™ä¸ªç±»åˆ«çš„ç´¢å¼•ï¼ˆæ¯”å¦‚æ²¡æœ‰ç¾å¦†æ•°æ®ï¼‰ï¼Œç›´æ¥è¿”å›ç©ºï¼Œä¸æŠ¥é”™
            return []

        target = self.partition_indexes[category]
        index = target['index']
        paths = target['paths']

        # 2. é¢„å¤„ç†å‘é‡ (ç¡®ä¿æ˜¯ 2D float32)
        if query_vector.ndim == 1:
            query_vector = query_vector.reshape(1, -1)
        query_vector = query_vector.astype('float32')

        # 3. æ™ºèƒ½è°ƒæ•´ Top-K
        # å¦‚æœè¯·æ±‚ 5 ä¸ªç»“æœï¼Œä½†è¯¥ç±»åˆ«åªæœ‰ 2 å¼ å›¾ï¼Œåˆ™åªæœ 2 å¼ ï¼Œé˜²æ­¢ FAISS æŠ¥é”™æˆ–è¿”å›å¡«å……å€¼
        real_k = min(top_k, len(paths))
        if real_k == 0:
            return []

        # 4. æ‰§è¡Œæœç´¢
        scores, indices = index.search(query_vector, real_k)

        results = []
        for score, idx in zip(scores[0], indices[0]):
            # FAISS å¯èƒ½ä¼šåœ¨æ‰¾ä¸åˆ°è¶³å¤Ÿç»“æœæ—¶è¿”å› -1ï¼Œå¿…é¡»è¿‡æ»¤
            if idx != -1 and idx < len(paths):
                results.append((paths[idx], float(score)))

        return results

    def describe_image(self, image_path: str, top_k: int = 3) -> List[Tuple[str, float]]:
        """
        æè¿°å›¾åƒï¼ˆæ‰¾åˆ°æœ€ç›¸ä¼¼çš„æ–‡æœ¬æè¿°ï¼‰
        """
        if self.text_index is None:
            return []

        # ç¼–ç æŸ¥è¯¢å›¾åƒ
        query_features = self.encode_images([image_path])

        # æœç´¢æœ€ç›¸ä¼¼çš„æ–‡æœ¬
        scores, indices = self.text_index.search(query_features.astype('float32'), top_k)

        results = []
        for score, idx in zip(scores[0], indices[0]):
            if idx < len(self.captions):
                results.append((self.captions[idx], float(score)))

        return results